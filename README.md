# ğŸ¦¾ GPS ë¯¸ì§€ì› í™˜ê²½ì„ ìœ„í•œ ì‹¤ì‹œê°„ ì„¼ì„œ ìœµí•©í˜• ì‹¤ë‚´ ìœ„ì¹˜ ì¶”ì • ì†”ë£¨ì…˜

> ### A real-time disaster rescue robot for GPS-denied environments using multi-sensor data fusion ### 
> *(LiDAR, IMU, Wheel Encoder, Camera, Temperature/Humidity)*  

---

## ğŸ”— Links    
- ğŸ“„ **Paper:** â€œ*Real-Time Disaster Rescue Robot for GPS-Denied Environments Using Multi-Sensor Data Fusion*,â€  
  *Korea Information Technology Society, Nov. 2025*  

---

## ğŸ§© Background  

Modern disaster environments often block GPS signals (e.g., tunnels, basements, or dense urban areas).  
This project proposes a **multi-sensor fusion robot system** capable of real-time localization, mapping, and autonomous navigation in such GPS-denied environments.  

### ğŸ¯ Key Objectives  
- ğŸ›°ï¸ Replace unreliable GPS data with **LiDARâ€“IMUâ€“Odometry fusion (LIO)**  
- âš™ï¸ Perform **real-time SLAM** and **path planning** on a **Linux-based ROS2 system**  
- â˜ï¸ Provide **cloud-based monitoring** through **MongoDB Atlas** and **Node-RED**  
- ğŸ§  Detect environmental hazards with **YOLOv5** and onboard cameras  

---

## âš™ï¸ Environment Setup  

| **Category** | **Details** |
|---------------|-------------|
| **OS** | Ubuntu 20.04 LTS |
| **Framework** | ROS2 Foxy, Navigation2, Cartographer |
| **Base Package** | Referenced the [STELLA_N2CAM_PI_X4PRO_ROS2_v2.0](https://github.com/ntrexlab/STELLA_N2CAM_PI_X4PRO_ROS2_v2.0) ROS2 package by NtrexLab
| **Programming** | Python 3, C++ |
| **Hardware** | Raspberry Pi 4, Stella N2 Robot |
| **Sensors** | LiDAR (YDLidar X4PRO), IMU (MW-AHRSv2U), Wheel Encoder, GPS (EZ-0048), Temp/Humidity Sensor |
| **Database / Monitoring** | MongoDB Atlas, Node-RED |
| **AI Model** | YOLOv5 (custom trained for obstacle detection) |

---

## ğŸ§  System Architecture  

### ğŸ§© System Overview  
<img width="972" alt="System Architecture" src="https://github.com/user-attachments/assets/5227d894-40b7-4a96-a4eb-fbb972524345" />

### âš™ï¸ Hardware  
<img width="959" alt="Hardware Diagram" src="https://github.com/user-attachments/assets/eaf8da6a-4658-474c-819f-b097c7bb600d" />

### ğŸ’» Software  
<img width="1337" alt="Software Diagram" src="https://github.com/user-attachments/assets/82e0d6e4-ddb8-4f9d-bc54-49870729c32b" />

### â˜ï¸ Node-RED Pipeline  
<img width="1893" alt="Node-RED Diagram" src="https://github.com/user-attachments/assets/62a25a0c-25c0-43c5-ba43-f65bd10baf42" />

---

## ğŸ§© Built With  

- **ROS2 (Foxy)** â€“ SLAM, Navigation, and real-time sensor fusion  
- **Cartographer** â€“ LiDAR-Inertial SLAM implementation  
- **YOLOv5** â€“ Real-time object detection for hazard identification  
- **MongoDB Atlas** â€“ Cloud data storage for live sensor updates  
- **Node-RED Dashboard** â€“ Web-based real-time monitoring  
- **Raspberry Pi 4 + Stella N2** â€“ Embedded control and execution platform  

---

## ğŸ¤– Robot Platform & Test Track  

### ğŸ§  Customized Robot System  
The robot platform was built using **Raspberry Pi 4**, **YDLidar X4PRO**, **MW-AHRSv2U IMU**, and **a custom chassis** for modular expansion.  
It integrates multiple sensors for real-time localization, mapping, and obstacle detection in disaster-like indoor environments.  

<img src="https://github.com/user-attachments/assets/a8fa8789-a0e9-48c7-bced-dc42487dbaaf" width="600" alt="Customized Robot" />

---

### ğŸ§­ Indoor Test Track  
To evaluate SLAM accuracy and navigation performance, a custom indoor track was designed to simulate **GPS-denied environments** such as tunnels and corridors.  
Obstacles were randomly placed to test dynamic path planning and YOLO-based hazard detection.  


<img src="https://github.com/user-attachments/assets/de58f297-f8d9-410e-862e-6fb62ddbb3e1" width="700" alt="Robot Track" />


---

## ğŸ“Š Results  

### ğŸ›°ï¸ End-to-end monitoring pipeline from robot â†’ cloud â†’ web in GPS-denied indoor environments  
<img width="1694" alt="Web Dashboard" src="https://github.com/user-attachments/assets/0c4860cf-5545-40ec-9fa9-354de3e2eee7" />

**Web Dashboard Features:**  
The web dashboard (built with **Node-RED** and **MongoDB Atlas**) provides a real-time visualization of all robot states and sensor data, enabling remote monitoring and control.  

- **SLAM Mapping:** Real-time 2D map generation via LiDARâ€“IMUâ€“Odometry fusion  
- **Trajectory Tracking:** Displays robot path, orientation (roll/pitch/yaw), and cumulative distance  
- **Object Detection:** YOLOv5-based real-time obstacle and hazard visualization through live camera feed  
- **Sensor Data Monitoring:** Live values for LiDAR range, IMU angular velocity, acceleration, GPS status, and temperature/humidity  
- **Alert System:** Visual warning when an obstacle is detected within 30 cm of the robot  
- **Cloud Synchronization:** Latest sensor data automatically updated to MongoDB in real time  
- **Indoor/Outdoor Detection:** GPS status indicator switches between indoor/outdoor based on signal availability  


ğŸ¥ **Result Video:** [YouTube Link](https://youtu.be/2Iq2_ShP6eY?si=E3-j7cPRBcZmXgdn)

---

## ğŸ† Award  
***Honorable Mention (KAIT Hanium Dream-Up ICT Competition 2025)***

---


